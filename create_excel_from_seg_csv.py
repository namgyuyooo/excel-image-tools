#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Create an Excel file from segmentation inference CSV and images.

Inputs:
- IMAGES_BASE: Base directory that contains image files organized by class folders
- CSV_PATH: CSV file with headers: img_path, origin_class, error, pred_seg_results, seg_score

Output:
- Excel file containing rows per image with embedded thumbnails and parsed predictions
"""

import os
import sys
import csv
import glob
import uuid
from typing import Dict, List, Tuple, Optional

from openpyxl import Workbook
from openpyxl.drawing import image as openpyxl_image
from PIL import Image as PILImage
from openpyxl.utils import get_column_letter


def normalize_relative_path(path_from_csv: str) -> str:
    """Normalize a CSV-provided image path to be relative to images base.

    Examples:
    - "20250801_v0.2/1.bondfinger/0001.jpg" -> "1.bondfinger/0001.jpg"
    - "1.bondfinger/0001.jpg" -> unchanged
    - Handles backslashes and redundant separators
    """
    if not path_from_csv:
        return ""
    norm = path_from_csv.replace("\\", "/")
    # If the first segment looks like a dataset date/version, drop it
    if "/" in norm:
        first, rest = norm.split("/", 1)
        # Heuristic: drop a leading segment that contains digits and dots/underscores like a version string
        if any(ch.isdigit() for ch in first):
            return rest
    return norm


def resolve_image_path(images_base: str, csv_img_path: str) -> Optional[str]:
    """Resolve CSV image path to an absolute path under images_base.

    Enhanced Strategy for new /1/ based folder structure:
    - ÏÉàÎ°úÏö¥ Í∏∞Î≥∏ Í≤ΩÎ°ú: /Users/yunamgyu/Downloads/test/1/0001/Unit/U0/BC
    - CSV File_pathÏóêÏÑú /1/ Ïù¥Ìïò ÏÉÅÎåÄ Í≤ΩÎ°ú Ï∂îÏ∂ú Î∞è Îß§Ïπ≠
    - /1/ Íµ¨Ï°∞Î•º Í≥†Î†§Ìïú Îã§Ï§ë Í≤ΩÎ°ú Í≤ÄÏÉâ

    Search patterns:
    1) /1/ Ïù¥Ìïò ÏÉÅÎåÄ Í≤ΩÎ°ú Ï∂îÏ∂ú Î∞è Í≤∞Ìï©
    2) /img Ìè¥ÎçîÏóêÏÑúÎèÑ Í≤ÄÏÉâ (Ïã§Ï†ú ÌååÏùº ÏúÑÏπò)
    3) Unit Ìè¥Îçî Í∞Ñ Îß§Ïπ≠ (U0, U9, U12 Îì±)
    4) ÌôïÏû•Ïûê Î≥ÄÌôò Î∞è Ïû¨Í∑Ä Í≤ÄÏÉâ
    """
    if not csv_img_path:
        return None

    # Ï†àÎåÄ Í≤ΩÎ°úÎ°ú Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏
    if os.path.isabs(csv_img_path) and os.path.exists(csv_img_path):
        return csv_img_path

    print(f"üîç Ìå®ÌÑ¥ Í∏∞Î∞ò Ï¥àÏú†Ïó∞ Îß§Ïπ≠ ÏãúÏûë: {csv_img_path}")

    # 0. Windows Î∞±Ïä¨ÎûòÏãúÎ•º Unix Ïä¨ÎûòÏãúÎ°ú Î≥ÄÌôò (ÏÉàÎ°úÏö¥ Ìå®ÌÑ¥ ÏßÄÏõê)
    normalized_csv_path = csv_img_path.replace('\\', '/')
    if normalized_csv_path != csv_img_path:
        print(f"üîÑ Windows Í≤ΩÎ°ú Î≥ÄÌôò: {csv_img_path} -> {normalized_csv_path}")
        csv_img_path = normalized_csv_path

    # 1. CSV Í≤ΩÎ°ú Íµ¨Ï°∞ Î∂ÑÏÑù Î∞è Ìå®ÌÑ¥ Ï∂îÏ∂ú
    import re

    # /Ïà´Ïûê/ Ìå®ÌÑ¥ Ï∂îÏ∂ú (Í∞úÏÑ†Îêú Ï†ïÍ∑úÏãù)
    number_pattern = re.search(r'/(\d+)/', csv_img_path)
    csv_structure = {}

    if number_pattern:
        csv_number = number_pattern.group(1)
        csv_structure['number'] = csv_number

        # /Ïà´Ïûê/ Ïù¥ÌõÑ Í≤ΩÎ°ú Î∂ÑÏÑù
        after_number = csv_img_path.split(f'/{csv_number}/', 1)[1]
        path_parts = after_number.split('/')

        if len(path_parts) >= 4:
            csv_structure.update({
                'part1': path_parts[0],  # 0001 (4ÏûêÎ¶¨ Ïà´Ïûê)
                'part2': path_parts[1],  # Unit (Í≥†Ï†ï)
                'part3': path_parts[2],  # U12, U70 Îì± (U+Ïà´Ïûê)
                'part4': path_parts[3],  # BC, FC Îì± (ÌÉÄÏûÖ)
                'filename': path_parts[-1] if len(path_parts) > 4 else path_parts[-1]
            })

        print(f"üìä CSV Íµ¨Ï°∞ Î∂ÑÏÑù: {csv_structure}")
        print(f"üéØ Îß§Ïπ≠ Ìå®ÌÑ¥: {csv_number}/{csv_structure.get('part1', '*')}/{csv_structure.get('part2', '*')}/{csv_structure.get('part3', 'U*')}/{csv_structure.get('filename', '*.jpg')}")

    # 2. Í∏∞Î≥∏ Í≤ΩÎ°ú Íµ¨Ï°∞ Î∂ÑÏÑù
    base_structure = {}
    base_number_pattern = re.search(r'/test/(\d+)/', images_base)
    if base_number_pattern:
        base_number = base_number_pattern.group(1)
        base_structure['number'] = base_number

        # Í∏∞Î≥∏ Í≤ΩÎ°úÏùò ÎÇòÎ®∏ÏßÄ Î∂ÄÎ∂Ñ Î∂ÑÏÑù
        after_base_number = images_base.split(f'/test/{base_number}/', 1)[1]
        base_path_parts = after_base_number.split('/')

        if len(base_path_parts) >= 4:
            base_structure.update({
                'part1': base_path_parts[0],
                'part2': base_path_parts[1],
                'part3': base_path_parts[2],
                'part4': base_path_parts[3],
            })

        print(f"üìä Í∏∞Î≥∏ Í≤ΩÎ°ú Íµ¨Ï°∞: {base_structure}")

    # 3. Ìå®ÌÑ¥ Í∏∞Î∞ò ÏµúÏ†ÅÌôî Îß§Ïπ≠
    search_patterns = []
    basename = os.path.basename(csv_img_path)
    base_no_ext, original_ext = os.path.splitext(basename)

    # Ïö∞ÏÑ†ÏàúÏúÑ 1: Ï†ïÌôïÌïú Íµ¨Ï°∞ Îß§Ïπ≠ (CSV Íµ¨Ï°∞Î•º Í∏∞Î≥∏ Í≤ΩÎ°úÏóê Ï†ÅÏö©)
    if csv_structure and base_structure:
        target_number = base_structure.get('number', csv_structure.get('number', '1'))

        # U* Ìå®ÌÑ¥ Ïö∞ÏÑ†: UÎ°ú ÏãúÏûëÌïòÎäî Ìè¥ÎçîÎßå Í≤ÄÏÉâ (ÏµúÏ†ÅÌôî)
        u_folders = []
        # Í∏∞Ï°¥ unit_folders + ÎèôÏ†Å ÏÉùÏÑ±
        base_u_folders = ['U0', 'U1', 'U2', 'U6', 'U7', 'U8', 'U9', 'U10', 'U11', 'U12', 'U13', 'U14', 'U15', 'U16', 'U19']

        # CSVÏùò U+Ïà´Ïûê Ìå®ÌÑ¥Ïù¥ ÏûàÎã§Î©¥ Ïö∞ÏÑ† Ï∂îÍ∞Ä
        if csv_structure.get('part3', '').startswith('U'):
            csv_u_folder = csv_structure['part3']
            if csv_u_folder not in base_u_folders:
                base_u_folders.insert(0, csv_u_folder)  # Ïö∞ÏÑ†ÏàúÏúÑ ÎÜíÏûÑ

        u_folders = base_u_folders
        type_folders = ['BC', 'FC', 'DC']

        # 4ÏûêÎ¶¨ Ïà´Ïûê Ïö∞ÏÑ† Îß§Ïπ≠ (0001, 0002 Îì±)
        part1_candidates = []
        if len(csv_structure.get('part1', '')) == 4 and csv_structure['part1'].isdigit():
            # CSVÏùò 4ÏûêÎ¶¨ Ïà´ÏûêÎ•º Ïö∞ÏÑ† ÏÇ¨Ïö©
            part1_candidates.append(csv_structure['part1'])
        part1_candidates.extend([base_structure.get('part1', '0001'), '0001', '0002', '0003'])

        for part1 in part1_candidates[:3]:  # ÏÉÅÏúÑ 3Í∞úÎßå
            for unit in u_folders[:10]:  # ÏÉÅÏúÑ 10Í∞ú U Ìè¥ÎçîÎßå (ÏÑ±Îä• ÏµúÏ†ÅÌôî)
                for type_folder in type_folders:
                    # Íµ¨Ï°∞ Í∏∞Î∞ò Í≤ΩÎ°ú ÏÉùÏÑ±
                    struct_path = f"{target_number}/{part1}/{base_structure.get('part2', 'Unit')}/{unit}/{type_folder}/{basename}"
                    search_patterns.append(os.path.join(images_base.split(f'/test/{base_structure.get("number", "1")}/')[0], "test", struct_path))

                    # /img Ìè¥ÎçîÏóêÏÑúÎèÑ Í≤ÄÏÉâ
                    img_base = images_base.replace('/test/', '/test/img/')
                    if img_base != images_base:
                        search_patterns.append(os.path.join(img_base.split(f'/test/img/{base_structure.get("number", "1")}/')[0], "test", "img", struct_path))

    # Ïö∞ÏÑ†ÏàúÏúÑ 2: p* Ìå®ÌÑ¥ Ïö∞ÏÑ† Í≤ÄÏÉâ (pÎ°ú ÏãúÏûëÌïòÎäî ÌååÏùºÎßå)
    if basename.startswith('p') or base_no_ext.startswith('p'):
        # pÎ°ú ÏãúÏûëÌïòÎäî ÌååÏùº Ìå®ÌÑ¥Îì§
        p_patterns = [
            os.path.join(images_base, "**", f"p*.{original_ext[1:]}" if original_ext else "p*"),
            os.path.join(images_base, "**", f"p*.jpg"),
            os.path.join(images_base, "**", f"p*.png"),
            os.path.join(images_base, "**", f"p*.bmp"),
        ]
        search_patterns.extend(p_patterns)

    # Ïö∞ÏÑ†ÏàúÏúÑ 3: Í∏∞Î≥∏ ÌååÏùºÎ™Ö Ìå®ÌÑ¥Îì§
    search_patterns.extend([
        os.path.join(images_base, "**", basename),
        os.path.join(images_base, "**", f"{base_no_ext}.*"),
    ])

    # 4. ÌôïÏû•Ïûê Î≥ÄÌôò Ìå®ÌÑ¥ Ï∂îÍ∞Ä (Ïö∞ÏÑ†ÏàúÏúÑ 4)
    ext_mapping = {
        '.bmp': ['.jpg', '.jpeg', '.png'],
        '.png': ['.jpg', '.jpeg', '.bmp'],
        '.jpg': ['.jpeg', '.png', '.bmp'],
        '.jpeg': ['.jpg', '.png', '.bmp']
    }

    if original_ext.lower() in ext_mapping:
        for new_ext in ext_mapping[original_ext.lower()]:
            search_patterns.extend([
                os.path.join(images_base, "**", f"{base_no_ext}{new_ext}"),
                os.path.join(images_base.replace('/test/', '/test/img/'), "**", f"{base_no_ext}{new_ext}")
            ])

    # 5. Ï§ëÎ≥µ Ï†úÍ±∞ Î∞è Ïö∞ÏÑ†ÏàúÏúÑ Ï†ïÎ†¨
    seen_patterns = set()
    unique_patterns = []
    for pattern in search_patterns:
        if pattern not in seen_patterns:
            seen_patterns.add(pattern)
            unique_patterns.append(pattern)

    print(f"üîç ÏÉùÏÑ±Îêú Í≤ÄÏÉâ Ìå®ÌÑ¥ Ïàò: {len(unique_patterns)} (Ïö∞ÏÑ†ÏàúÏúÑ ÏµúÏ†ÅÌôî)")

    # 6. Ïã§Ï†ú Í≤ÄÏÉâ ÏàòÌñâ (Ïö∞ÏÑ†ÏàúÏúÑ Í∏∞Î∞ò)
    all_matches = []

    # Ïö∞ÏÑ†ÏàúÏúÑ Í∑∏Î£πÎ≥Ñ Í≤ÄÏÉâ
    priority_groups = [
        unique_patterns[:10],    # Íµ¨Ï°∞ Îß§Ïπ≠ Ïö∞ÏÑ† (ÏÉÅÏúÑ 10Í∞ú)
        unique_patterns[10:30],  # p* Ìå®ÌÑ¥ (Îã§Ïùå 20Í∞ú)
        unique_patterns[30:50],  # Í∏∞Î≥∏ Ìå®ÌÑ¥ (Îã§Ïùå 20Í∞ú)
        unique_patterns[50:70],  # ÌôïÏû•Ïûê Î≥ÄÌôò (Îã§Ïùå 20Í∞ú)
    ]

    for group_idx, group in enumerate(priority_groups):
        if not group:
            continue

        print(f"üéØ Ïö∞ÏÑ†ÏàúÏúÑ Í∑∏Î£π {group_idx + 1} Í≤ÄÏÉâ Ï§ë...")
        for pattern in group:
            try:
                if os.path.exists(pattern):
                    print(f"‚úÖ Ïö∞ÏÑ†ÏàúÏúÑ {group_idx + 1} - ÏßÅÏ†ë Í≤ΩÎ°ú Îß§Ïπò: {pattern}")
                    return pattern

                matches = glob.glob(pattern, recursive=True)
                if matches:
                    for match in matches:
                        match_basename = os.path.basename(match)
                        if match_basename == basename:
                            print(f"‚úÖ Ïö∞ÏÑ†ÏàúÏúÑ {group_idx + 1} - Ï†ïÌôïÌïú ÌååÏùºÎ™Ö Îß§Ïπò: {match}")
                            return match
                        all_matches.append(match)
            except:
                continue

    # 7. Îß§Ïπò Í≤∞Í≥º Î∞òÌôò
    if all_matches:
        best_match = all_matches[0]
        print(f"‚úÖ Íµ¨Ï°∞ Í∏∞Î∞ò Îß§Ïπ≠ ÏÑ±Í≥µ: {best_match}")
        return best_match

    print(f"‚ùå Î™®Îì† Ìå®ÌÑ¥ÏúºÎ°ú Í≤ÄÏÉâÌñàÏúºÎÇò ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏùå: {basename}")
    return None


def find_viz_image(original_image_path: str) -> Optional[str]:
    """Try to find a corresponding visualization image near the original image.

    Looks for variants like:
    - <name>_viz.png
    - <name>_viz.jpg/jpeg
    - any *<name>*viz*.png in the same directory
    """
    if not original_image_path:
        return None
    directory = os.path.dirname(original_image_path)
    base, _ = os.path.splitext(os.path.basename(original_image_path))

    candidates = [
        os.path.join(directory, f"{base}_viz.png"),
        os.path.join(directory, f"{base}_viz.jpg"),
        os.path.join(directory, f"{base}_viz.jpeg"),
    ]
    for cand in candidates:
        if os.path.exists(cand):
            return cand

    wildcard = glob.glob(os.path.join(directory, f"*{base}*viz*.png"))
    if wildcard:
        return wildcard[0]

    return None


def parse_prediction_fields(pred_seg_results: str, seg_score: str) -> Tuple[str, str, str, str]:
    """Parse semicolon-separated predictions and scores.

    Returns: (top_pred, top_score, all_preds, all_scores)
    """
    preds = [p.strip() for p in (pred_seg_results or "").split(";") if p.strip()]
    scores = [s.strip() for s in (seg_score or "").split(";") if s.strip()]

    top_pred = preds[0] if preds else ""
    top_score = scores[0] if scores else ""
    all_preds = "; ".join(preds)
    all_scores = "; ".join(scores)
    return top_pred, top_score, all_preds, all_scores


def create_excel_from_csv(images_base: str, csv_path: str, output_file: str, limit: Optional[int] = None) -> bool:
    """Create an Excel workbook that mirrors the CSV columns and appends one last image column.

    limit: cap the number of rows processed (None for all)
    """
    wb = Workbook()
    ws = wb.active
    ws.title = "inference_results"

    temp_files: List[str] = []

    with open(csv_path, 'r', encoding='utf-8-sig') as f:
        reader = csv.DictReader(f)
        fieldnames: List[str] = reader.fieldnames or []

        # Headers = CSV headers + last image column
        headers = fieldnames + ["img"]
        for col_index, name in enumerate(headers, start=1):
            ws.cell(row=1, column=col_index, value=name)

        # Make the last column wide for images
        last_col_letter = get_column_letter(len(headers))
        ws.column_dimensions[last_col_letter].width = 30

        current_row = 2
        for i, row in enumerate(reader):
            if limit is not None and i >= limit:
                break

            # Write CSV fields as-is in order
            for col_index, key in enumerate(fieldnames, start=1):
                ws.cell(row=current_row, column=col_index, value=row.get(key, ""))

            # Resolve and insert image at the last column
            csv_img_path = row.get('img_path', '')
            abs_img_path = resolve_image_path(images_base, csv_img_path)

            # Set row height for image visibility
            ws.row_dimensions[current_row].height = 180

            image_col_letter = last_col_letter
            if abs_img_path and os.path.exists(abs_img_path):
                try:
                    temp_img_path = f"temp_img_{uuid.uuid4().hex[:8]}.png"
                    with PILImage.open(abs_img_path) as pil_img:
                        if pil_img.mode != 'RGB':
                            pil_img = pil_img.convert('RGB')
                        pil_img.thumbnail((300, 300), PILImage.Resampling.LANCZOS)
                        pil_img.save(temp_img_path, "PNG")
                    temp_files.append(temp_img_path)

                    img = openpyxl_image.Image(temp_img_path)
                    img.width = 180
                    img.height = 180
                    img.anchor = f'{image_col_letter}{current_row}'
                    ws.add_image(img)
                except Exception as e:
                    ws[f'{image_col_letter}{current_row}'] = f"Error: {e}"
            else:
                ws[f'{image_col_letter}{current_row}'] = "Image not found"

            current_row += 1

    wb.save(output_file)

    for path in temp_files:
        try:
            if os.path.exists(path):
                os.unlink(path)
        except Exception:
            pass

    return True


def main():
    # Configure your paths here (can be turned into CLI args if needed)
    IMAGES_BASE = \
        "/Users/rtm/Downloads/seg/v0.3_inference_20250801_v0.2/images"
    CSV_PATH = \
        "/Users/rtm/Downloads/seg/v0.3_inference_20250801_v0.2/inference_results.csv"

    output_file = \
        "/Users/rtm/Downloads/seg/v0.3_inference_20250801_v0.2/inference_results_with_image.xlsx"

    # Safety checks
    if not os.path.isdir(IMAGES_BASE):
        print(f"‚ùå Images base directory not found: {IMAGES_BASE}")
        sys.exit(1)
    if not os.path.isfile(CSV_PATH):
        print(f"‚ùå CSV file not found: {CSV_PATH}")
        sys.exit(1)

    print("üìÅ Images base:", IMAGES_BASE)
    print("üìÑ CSV path:", CSV_PATH)
    print("üìä Output:", output_file)

    success = create_excel_from_csv(IMAGES_BASE, CSV_PATH, output_file, limit=None)
    if success:
        print(f"‚úÖ Excel created: {output_file}")
    else:
        print("‚ùå Failed to create Excel")
        sys.exit(1)


if __name__ == "__main__":
    main()


